{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptKxT-xOqa3h"
      },
      "outputs": [],
      "source": [
        "# 1. What is Simple Linear Regression?\n",
        "'''Simple Linear Regression is a statistical method used to understand the relationship between two variables:\n",
        "one independent variable (X) and one dependent variable (Y), using a straight-line equation.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. What are the key assumptions of Simple Linear Regression?\n",
        "'''Linearity: The relationship between variables is linear.\n",
        "Independence: Observations are independent of each other.\n",
        "Homoscedasticity: Constant variance of errors.\n",
        "Normality: Errors are normally distributed.'''"
      ],
      "metadata": {
        "id": "ezuo2Pdos77E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. What does the coefficient m represent in the equation Y=mX+c?\n",
        "'''m is the slope ‚Äî it shows how much Y changes for a one-unit increase in X.'''"
      ],
      "metadata": {
        "id": "N8DBjfO-s78z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. What does the intercept c represent in the equation Y=mX+c?\n",
        "'''c is the intercept ‚Äî the value of Y when X is 0.'''"
      ],
      "metadata": {
        "id": "t4-eyfXls8CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. How do we calculate the slope m in Simple Linear Regression?\n",
        "'''least squares method to calculate the best slope ùúÉ1:\n",
        "Œ∏1 = ‚àë(xi‚àí xÀâ)(yi‚àí yÀâ)/‚àë(xi‚àí xÀâ)2"
      ],
      "metadata": {
        "id": "I0zO9C04s8DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "'''It minimizes the sum of the squared differences between observed and predicted values, ensuring the best-fitting line.'''"
      ],
      "metadata": {
        "id": "aRVaNoVNs8Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?\n",
        "'''R¬≤ indicates how well the regression line fits the data. A value close to 1 means a good fit; close to 0 means a poor fit.'''"
      ],
      "metadata": {
        "id": "icr0ukr6s8Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. What is Multiple Linear Regression?\n",
        "'''A regression model with two or more independent variables predicting a single dependent variable.'''"
      ],
      "metadata": {
        "id": "EeS26IY-s8MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. What is the main difference between Simple and Multiple Linear Regressio?\n",
        "'''Simple: 1 independent variable.\n",
        "Multiple: 2 or more independent variables.'''"
      ],
      "metadata": {
        "id": "HKgdtfzXs8OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. What are the key assumptions of Multiple Linear Regression?\n",
        "'''Linearity: The relationship between variables is linear.\n",
        "Independence: Observations are independent of each other.\n",
        "Homoscedasticity: Constant variance of errors.\n",
        "Normality: Errors are normally distributed.\n",
        "\n",
        "No multicollinearity (independent variables shouldn't be highly correlated).\n",
        "No auto-correlation of residuals.''"
      ],
      "metadata": {
        "id": "eSe9mkqss8Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "'''Heteroscedasticity means errors have non-constant variance.\n",
        "It can lead to inefficient estimates and invalid hypothesis tests.'''"
      ],
      "metadata": {
        "id": "GXkRsoYus8UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "'''Remove or combine correlated variables, or use techniques like Ridge or Lasso regression."
      ],
      "metadata": {
        "id": "HXqIyPIss8ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "'''One-hot encoding, Label encoding, Dummy variables'''"
      ],
      "metadata": {
        "id": "raBn4Vsvs8ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "'''Interaction terms capture the combined effect of two or more variables on the dependent variable,\n",
        "which might not be apparent when considering variables individually.'''"
      ],
      "metadata": {
        "id": "i17fWKm3s8gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "'''In Simple: It's Y when X = 0.\n",
        "In Multiple: It's Y when all Xs = 0, which may not be meaningful.'''"
      ],
      "metadata": {
        "id": "0KuY4gtos8hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "'''The slope indicates the change in the dependent variable for a one-unit change in the independent variable.\n",
        "\n",
        "A positive slope means Y increases as X increases, while a negative slope means Y decreases as X increases.\n",
        "\n",
        "The slope determines how steep the prediction line is and directly affects predictions by controlling\n",
        "how much the predicted value changes for each change in X.'''"
      ],
      "metadata": {
        "id": "H8sx_t1ws8lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "'''It sets the baseline value of Y when predictors are zero, giving a starting point for predictions.'''"
      ],
      "metadata": {
        "id": "GUor5HBTs8nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. What are the limitations of using R¬≤ as a sole measure of model performance?\n",
        "'''R¬≤ always increases with more variables, so it can be misleading without considering adjusted R¬≤ or other metrics.'''"
      ],
      "metadata": {
        "id": "VofvQtr0s8sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. How would you interpret a large standard error for a regression coefficient?\n",
        "'''It means less confidence in the estimate; the coefficient may not be statistically significant.'''"
      ],
      "metadata": {
        "id": "1Bz-OSUcs8uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "'''If residuals spread out unevenly across fitted values, it indicates heteroscedasticity.\n",
        "It's important because it violates regression assumptions and affects inference.'''"
      ],
      "metadata": {
        "id": "cac-2DUks8zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?\n",
        "'''It suggests overfitting, where many variables don‚Äôt actually improve the model.'''"
      ],
      "metadata": {
        "id": "BYkTvl4ns81D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "'''Scaling ensures all variables contribute equally, improves convergence in optimization, and helps interpret coefficients.''''"
      ],
      "metadata": {
        "id": "HqcUwNj9s88J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. What is polynomial regression?\n",
        "'''A regression technique where the relationship between the independent variable and dependent variable is modeled as an nth-degree polynomial.'''"
      ],
      "metadata": {
        "id": "Kq007IP5s89Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. How does polynomial regression differ from linear regression?\n",
        "'''Polynomial regression fits a curved line (non-linear), while linear regression fits a straight line.'''"
      ],
      "metadata": {
        "id": "svL8-8iPs9C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25. When is polynomial regression used?\n",
        "'''When data shows a non-linear relationship that a straight line can't fit well.'''"
      ],
      "metadata": {
        "id": "QVNeQ1T5s9Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 26. What is the general equation for polynomial regression?\n",
        "'''Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œ≤‚ÇÇX¬≤ + ... + Œ≤‚ÇôX‚Åø'''"
      ],
      "metadata": {
        "id": "jvp19X39s9JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 27. Can polynomial regression be applied to multiple variables?\n",
        "'''Yes, by adding polynomial terms for each variable, but it increases model complexity.'''"
      ],
      "metadata": {
        "id": "gZfyOqGzs9LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 28. What are the limitations of polynomial regression?\n",
        "'''Risk of overfitting, especially with higher-degree polynomials.'''"
      ],
      "metadata": {
        "id": "VX3vg6LBs9Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "'''Cross-validation, adjusted R¬≤, AIC, BIC, and residual analysis.'''"
      ],
      "metadata": {
        "id": "d46b64QPvPjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 30. Why is visualization important in polynomial regression?\n",
        "'''It helps understand the fit of the curve to data and detect overfitting or underfitting.'''"
      ],
      "metadata": {
        "id": "egTw88tKvPhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 31. How is polynomial regression implemented in Python?\n",
        "'''Using libraries like numpy for polynomial features or sklearn.preprocessing.\n",
        "PolynomialFeatures combined with linear regression.'''"
      ],
      "metadata": {
        "id": "Rw7RnV98vT6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}